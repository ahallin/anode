{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The top-level PyTorch package and tensor library\n",
    "import torch \n",
    "\n",
    "# A subpackage that contains modules and extensible \n",
    "# classes for building neural networks. \n",
    "import torch.nn as nn\n",
    "\n",
    "# A subpackage that contains standard optimization \n",
    "# operations like SGD and Adam. \n",
    "import torch.optim as optim\n",
    "\n",
    "# A functional interface that contains typical operations \n",
    "# used for building neural networks like loss functions \n",
    "# and convolutions. \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm # progress meter\n",
    "import flows as fnn # imports the module flows.py, which you have in this directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 2)\n"
     ]
    }
   ],
   "source": [
    "mu, sigma = 0, np.array([0.1,0.2,0.5]) # mean and standard deviation\n",
    "pts = 10000 # number of data points\n",
    "\n",
    "def p(i):\n",
    "    rand = np.random.normal(mu, sigma[i], pts)\n",
    "    stack = np.dstack((rand, sigma[i]*np.ones(len(rand))))\n",
    "    return stack.reshape(-1,2)\n",
    "\n",
    "#vecp = np.vectorize(p) THIS DOES NOT WORK pga ORDER OF OPERATIONS\n",
    "\n",
    "datan = np.vstack((p(0),p(1),p(2)))\n",
    "\n",
    "print(np.shape(datan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(datan[20000:30000,0], bins = 100, fc=(1, 0, 0, 0.5), alpha=0.3, label='0.5')\n",
    "plt.hist(datan[10000:20000,0], bins = 100, fc=(0, 1, 1, 0.5), alpha=0.2, label='0.2')\n",
    "plt.hist(datan[:10000,0], bins = 50, fc=(1, 0, 1, 0.5), alpha=0.2, label='0.1')\n",
    "plt.xlim(-1,1)\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Indices and shuffling'''\n",
    "\n",
    "# Create an array of indices, of length data, and shuffle it\n",
    "indices = np.array(range(len(datan))).astype('int') \n",
    "np.random.shuffle(indices)\n",
    "# print(indices[:10],len(indices)) -- ok it works\n",
    "\n",
    "datan = datan[indices] \n",
    "# print(datan[:10]) -- ok it works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data Sets and Data Loaders'''\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "labels = torch.from_numpy(datan[:,1:2])\n",
    "prob_data = torch.from_numpy(datan[:,0:1])\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(prob_data, labels)\n",
    "# Compared to anode: \n",
    "# The first argument is x (probably density data) and the second \n",
    "# is mjj (conditioned data)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_inputs = prob_data.shape[-1]\n",
    "num_cond_inputs = labels.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAF pars 15 128\n"
     ]
    }
   ],
   "source": [
    "''' ====================================================================== '''\n",
    "''' model parameters '''\n",
    "''' ====================================================================== '''\n",
    "\n",
    "flow='maf' # MAF is what is being used in the training\n",
    "batch_size = 256\n",
    "test_batch_size = 10*batch_size\n",
    "num_blocks = 15\n",
    "num_hidden = 128\n",
    "lr = 1e-4 # I assume this is learning rate\n",
    "\n",
    "print('MAF pars',num_blocks,num_hidden)\n",
    "\n",
    "CUDA = False #CUDA is a parallel computing platform and application programming interface model created by Nvidia. It allows software developers and software engineers to use a CUDA-enabled graphics processing unit for general purpose processing\n",
    "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if CUDA else {}\n",
    "kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ====================================================================== '''\n",
    "''' define training function '''\n",
    "''' ====================================================================== '''\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "def train(epoch):\n",
    "    global global_step\n",
    "    model.train() \n",
    "    train_loss = 0\n",
    "\n",
    "    # make your loops show a smart progress meter - just wrap any iterable with tqdm(iterable)\n",
    "    pbar = tqdm(total=len(loader.dataset)) \n",
    "    \n",
    "    for batch_idx, data in enumerate(loader):\n",
    "        if isinstance(data, list):\n",
    "            if len(data) > 1:\n",
    "                cond_data = data[1].float() # Assigns the 2nd element in data as the conditioned data\n",
    "                cond_data = cond_data.to(device) # Sends conditioned data to the GPU\n",
    "            else:\n",
    "                cond_data = None\n",
    "\n",
    "            data = data[0] # Assigns the 1st element in data as the data points\n",
    "        data = data.to(device) # Sends the data to the GPU\n",
    "\n",
    "        optimizer.zero_grad() # need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
    "        # print(data, cond_data)\n",
    "        loss = -model.log_probs(data, cond_data).mean()\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.update(data.size(0))\n",
    "        pbar.set_description('Train, Log likelihood in nats: {:.6f}'.format(\n",
    "            -train_loss / (batch_idx + 1)))\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, fnn.BatchNormFlow):\n",
    "            module.momentum = 0\n",
    "\n",
    "    # The with statement itself ensures proper acquisition and release of resources.        \n",
    "    # Disabling gradient calculation is useful for inference, when you are sure that you will not call Tensor.backward(). It will reduce memory consumption for computations that would otherwise have requires_grad=True.\n",
    "    with torch.no_grad(): \n",
    "        model(loader.dataset.tensors[0].to(data.device),\n",
    "            loader.dataset.tensors[1].to(data.device).float())\n",
    "\n",
    "    # If you want to recursively iterate over modules, then you want to use .modules()    \n",
    "    for module in model.modules():\n",
    "        if isinstance(module, fnn.BatchNormFlow):\n",
    "            module.momentum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ====================================================================== '''\n",
    "''' Define model '''\n",
    "''' ====================================================================== '''\n",
    "\n",
    "act = 'relu'\n",
    "\n",
    "modules = []\n",
    "for _ in range(num_blocks):\n",
    "    modules += [\n",
    "        fnn.MADE(num_inputs, num_hidden, num_cond_inputs, act=act),\n",
    "        fnn.BatchNormFlow(num_inputs),\n",
    "        fnn.Reverse(num_inputs)\n",
    "    ]\n",
    "\n",
    "model = fnn.FlowSequential(*modules)\n",
    "for module in model.modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.orthogonal_(module.weight)\n",
    "        if hasattr(module, 'bias') and module.bias is not None:\n",
    "            module.bias.data.fill_(0)\n",
    "model.to(device)\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ====================================================================== '''\n",
    "''' Train model '''\n",
    "''' ====================================================================== '''\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch: {}'.format(epoch))\n",
    "    train(epoch)\n",
    "    torch.save(model.state_dict(),modellen+\"_\"+label+\"_epoch_\"+str(epoch)+\".par\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to use it yourself for inference: You save the model, you restore it, and then you change the model to evaluation mode. This is done because you usually have BatchNorm and Dropout layers that by default are in train mode on construction:\n",
    "\n",
    "torch.save(model.state_dict(), filepath)\n",
    "\n",
    "#Later to restore:\n",
    "\n",
    "model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch\n",
    "\n",
    "Du använder filepath=modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old things I've tried "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.1 0.2 0.5]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-90a8d66c8eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mvecp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvecp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0motypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m                 res = tuple([array(x, copy=False, subok=True, dtype=t)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "''' Create data '''\n",
    "\n",
    "mu, sigma = 0, np.array([0.1,0.2,0.5]) # mean and standard deviation\n",
    "print(mu,sigma)\n",
    "\n",
    "def p(s):\n",
    "    rand = np.random.normal(mu, s, 10)\n",
    "    #return np.dstack((rand, s*np.ones(len(rand))))\n",
    "    #return np.array([rand,s],dtype = np.float32)\n",
    "    #return np.append(rand,s)\n",
    "    #ret = np.array([rand,s])\n",
    "    return np.shape(rand)\n",
    "\n",
    "'''def p(s):\n",
    "    def pp(k):\n",
    "        rand = np.random.normal(mu, k, 10)\n",
    "        return np.dstack((rand, k*np.ones(len(rand))))\n",
    "    #return np.array([rand,s],dtype = np.float32)\n",
    "    #return np.append(rand,s)\n",
    "    #ret = np.array([rand,s])\n",
    "    #return np.shape(rand)\n",
    "    return pp(s)'''\n",
    "\n",
    "vecp = np.vectorize(p)\n",
    "\n",
    "data = vecp(sigma)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
